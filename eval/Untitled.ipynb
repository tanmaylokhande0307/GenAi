{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a2e6d3-3c3a-4dc0-9e26-da2202d275c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --user --quiet google-cloud-aiplatform[rapid_evaluation]\n",
    "%pip install --quiet --upgrade nest_asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bba5844-5449-4c4a-804b-e97a3c3608c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8204e804-9d64-4b48-812d-d0733b27fe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip --quiet install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07480f0e-d69a-4cf2-861c-7e7f5ec3e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb67e5ed-19b1-44ca-94f6-a825e686c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c05924bf-e7a4-4cd6-9fbf-79f91d23989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"gemini-api-428204\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c6c1f5-9087-495c-b402-e2472ebef3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from uuid import uuid4\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import nest_asyncio\n",
    "import warnings\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "\n",
    "# Main\n",
    "import vertexai\n",
    "from vertexai.preview.evaluation import (\n",
    "    EvalTask,\n",
    "    PromptTemplate,\n",
    "    CustomMetric,\n",
    "    make_metric,\n",
    ")\n",
    "import pandas as pd\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "from vertexai.generative_models import GenerativeModel, HarmCategory, HarmBlockThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "946ffecd-d847-42d5-a473-ac1268eea308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.getLogger(\"urllib3.connectionpool\").setLevel(logging.ERROR)\n",
    "nest_asyncio.apply()\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c991b859-afea-4cf8-a418-4d5fcebd0483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uuid(length: int = 8) -> str:\n",
    "    \"\"\"Generate a uuid of a specified length (default=8).\"\"\"\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "def print_doc(function):\n",
    "    print(f\"{function.__name__}:\\n{inspect.getdoc(function)}\\n\")\n",
    "\n",
    "\n",
    "def display_eval_report(eval_result, metrics=None):\n",
    "    \"\"\"Display the evaluation results.\"\"\"\n",
    "\n",
    "    title, summary_metrics, report_df = eval_result\n",
    "    metrics_df = pd.DataFrame.from_dict(summary_metrics, orient=\"index\").T\n",
    "    if metrics:\n",
    "        metrics_df = metrics_df.filter(\n",
    "            [\n",
    "                metric\n",
    "                for metric in metrics_df.columns\n",
    "                if any(selected_metric in metric for selected_metric in metrics)\n",
    "            ]\n",
    "        )\n",
    "        report_df = report_df.filter(\n",
    "            [\n",
    "                metric\n",
    "                for metric in report_df.columns\n",
    "                if any(selected_metric in metric for selected_metric in metrics)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Display the title with Markdown for emphasis\n",
    "    display(Markdown(f\"## {title}\"))\n",
    "\n",
    "    # Display the metrics DataFrame\n",
    "    display(Markdown(\"### Summary Metrics\"))\n",
    "    display(metrics_df)\n",
    "\n",
    "    # Display the detailed report DataFrame\n",
    "    display(Markdown(f\"### Report Metrics\"))\n",
    "    display(report_df)\n",
    "\n",
    "\n",
    "def display_explanations(df, metrics=None, n=1):\n",
    "    style = \"white-space: pre-wrap; width: 800px; overflow-x: auto;\"\n",
    "    df = df.sample(n=n)\n",
    "    if metrics:\n",
    "        df = df.filter(\n",
    "            [\"instruction\", \"context\", \"reference\", \"completed_prompt\", \"response\"]\n",
    "            + [\n",
    "                metric\n",
    "                for metric in df.columns\n",
    "                if any(selected_metric in metric for selected_metric in metrics)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        for col in df.columns:\n",
    "            display(HTML(f\"{col}: {row[col]}\"))\n",
    "        display(HTML(\"\"))\n",
    "\n",
    "\n",
    "def plot_radar_plot(eval_results, metrics=None):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for eval_result in eval_results:\n",
    "        title, summary_metrics, report_df = eval_result\n",
    "\n",
    "        if metrics:\n",
    "            summary_metrics = {\n",
    "                k: summary_metrics[k]\n",
    "                for k, v in summary_metrics.items()\n",
    "                if any(selected_metric in k for selected_metric in metrics)\n",
    "            }\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatterpolar(\n",
    "                r=list(summary_metrics.values()),\n",
    "                theta=list(summary_metrics.keys()),\n",
    "                fill=\"toself\",\n",
    "                name=title,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        polar=dict(radialaxis=dict(visible=True, range=[0, 5])), showlegend=True\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_bar_plot(eval_results, metrics=None):\n",
    "    fig = go.Figure()\n",
    "    data = []\n",
    "\n",
    "    for eval_result in eval_results:\n",
    "        title, summary_metrics, _ = eval_result\n",
    "        if metrics:\n",
    "            summary_metrics = {\n",
    "                k: summary_metrics[k]\n",
    "                for k, v in summary_metrics.items()\n",
    "                if any(selected_metric in k for selected_metric in metrics)\n",
    "            }\n",
    "\n",
    "        data.append(\n",
    "            go.Bar(\n",
    "                x=list(summary_metrics.keys()),\n",
    "                y=list(summary_metrics.values()),\n",
    "                name=title,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig = go.Figure(data=data)\n",
    "\n",
    "    # Change the bar mode\n",
    "    fig.update_layout(barmode=\"group\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def print_aggregated_metrics(job):\n",
    "    \"\"\"Print AutoMetrics\"\"\"\n",
    "\n",
    "    rougeLSum = round(job.rougeLSum, 3) * 100\n",
    "    display(\n",
    "        HTML(\n",
    "            f\"The {rougeLSum}% of the reference summary is represented by LLM when considering the longest common subsequence (LCS) of words.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def print_autosxs_judgments(df, n=3):\n",
    "    \"\"\"Print AutoSxS judgments in the notebook\"\"\"\n",
    "\n",
    "    style = \"white-space: pre-wrap; width: 800px; overflow-x: auto;\"\n",
    "    df = df.sample(n=n)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"confidence\"] >= 0.5:\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"Document: {row['id_columns']['document']}\"\n",
    "                )\n",
    "            )\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"Response A: {row['response_a']}\"\n",
    "                )\n",
    "            )\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"Response B: {row['response_b']}\"\n",
    "                )\n",
    "            )\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"Explanation: {row['explanation']}\"\n",
    "                )\n",
    "            )\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"Confidence score: {row['confidence']}\"\n",
    "                )\n",
    "            )\n",
    "            display(HTML(\"\"))\n",
    "\n",
    "\n",
    "def print_autosxs_win_metrics(scores):\n",
    "    \"\"\"Print AutoSxS aggregated metrics\"\"\"\n",
    "\n",
    "    score_b = round(scores[\"autosxs_model_b_win_rate\"] * 100)\n",
    "    display(\n",
    "        HTML(\n",
    "            f\"AutoSxS Autorater prefers {score_b}% of time Model B over Model A \"\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1099958e-a6ab-4d98-b876-7e48b7243b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-acd87f45-538b-4932-a9ae-1bd7f0d04400\" href=\"#view-view-vertex-resource-acd87f45-538b-4932-a9ae-1bd7f0d04400\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-acd87f45-538b-4932-a9ae-1bd7f0d04400');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/qa-eval-01/runs?project=gemini-api-428204');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/qa-eval-01/runs?project=gemini-api-428204', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/584767023807/locations/us-central1/metadataStores/default/contexts/qa-eval-01-gemini-pro-for-qa-e7f1383d-3851-48f0-9ff9-d15cd5c55bc4 to Experiment: qa-eval-01\n",
      "Logging Rapid Eval experiment metadata: {'model_name': 'publishers/google/models/phi-3', 'temperature': 0.8, 'top_k': 1}\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "404 Publisher Model `projects/gemini-api-428204/locations/us-central1/publishers/google/models/phi-3` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/grpc/_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1175\u001b[0m (\n\u001b[1;32m   1176\u001b[0m     state,\n\u001b[1;32m   1177\u001b[0m     call,\n\u001b[1;32m   1178\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1179\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1180\u001b[0m )\n\u001b[0;32m-> 1181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"Publisher Model `projects/gemini-api-428204/locations/us-central1/publishers/google/models/phi-3` not found.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2404:6800:4009:831::200a%5D:443 {created_time:\"2024-07-10T14:16:43.765207457+05:30\", grpc_status:5, grpc_message:\"Publisher Model `projects/gemini-api-428204/locations/us-central1/publishers/google/models/phi-3` not found.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m\n\u001b[1;32m     17\u001b[0m qa_eval_task \u001b[38;5;241m=\u001b[39m EvalTask(\n\u001b[1;32m     18\u001b[0m     dataset\u001b[38;5;241m=\u001b[39meval_dataset,\n\u001b[1;32m     19\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafety\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_generation_quality\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     20\u001b[0m     experiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqa-eval-01\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m gemini_model_for_qa \u001b[38;5;241m=\u001b[39m GenerativeModel(\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi-3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     },\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mqa_eval_task\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgemini_model_for_qa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_run_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini-pro-for-qa-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muuid4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     33\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/vertexai/preview/evaluation/_eval_tasks.py:339\u001b[0m, in \u001b[0;36mEvalTask.evaluate\u001b[0;34m(self, model, prompt_template, experiment_run_name, response_column_name)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_experiment_name:\n\u001b[1;32m    336\u001b[0m     metadata\u001b[38;5;241m.\u001b[39m_experiment_tracker\u001b[38;5;241m.\u001b[39mset_experiment(\n\u001b[1;32m    337\u001b[0m         experiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment, backing_tensorboard\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    338\u001b[0m     )\n\u001b[0;32m--> 339\u001b[0m     eval_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_with_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_run_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_column_name\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     metadata\u001b[38;5;241m.\u001b[39m_experiment_tracker\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment \u001b[38;5;129;01mand\u001b[39;00m global_experiment_name:\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/vertexai/preview/evaluation/_eval_tasks.py:273\u001b[0m, in \u001b[0;36mEvalTask._evaluate_with_experiment\u001b[0;34m(self, model, prompt_template, experiment_run_name, response_column_name)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vertexai\u001b[38;5;241m.\u001b[39mpreview\u001b[38;5;241m.\u001b[39mstart_run(experiment_run_name):\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_eval_experiment_param(model, prompt_template)\n\u001b[0;32m--> 273\u001b[0m     eval_result \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreference_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_column_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m         vertexai\u001b[38;5;241m.\u001b[39mpreview\u001b[38;5;241m.\u001b[39mlog_metrics(eval_result\u001b[38;5;241m.\u001b[39msummary_metrics)\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/vertexai/preview/evaluation/_evaluation.py:543\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, metrics, model, prompt_template, content_column_name, reference_column_name, response_column_name, context_column_name, instruction_column_name)\u001b[0m\n\u001b[1;32m    538\u001b[0m     evaluation_run_config\u001b[38;5;241m.\u001b[39mvalidate_dataset_column(\n\u001b[1;32m    539\u001b[0m         constants\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mCONTENT_COLUMN\n\u001b[1;32m    540\u001b[0m     )\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, generative_models\u001b[38;5;241m.\u001b[39mGenerativeModel):\n\u001b[0;32m--> 543\u001b[0m     \u001b[43m_generate_response_from_gemini_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_run_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(model):\n\u001b[1;32m    545\u001b[0m     _generate_response_from_custom_model_fn(model, evaluation_run_config)\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/vertexai/preview/evaluation/_evaluation.py:263\u001b[0m, in \u001b[0;36m_generate_response_from_gemini_model\u001b[0;34m(model, evaluation_run_config)\u001b[0m\n\u001b[1;32m    251\u001b[0m     evaluation_run_config\u001b[38;5;241m.\u001b[39mdataset[\n\u001b[1;32m    252\u001b[0m         constants\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mMODEL_RESPONSE_COLUMN\n\u001b[1;32m    253\u001b[0m     ] \u001b[38;5;241m=\u001b[39m evaluation_run_config\u001b[38;5;241m.\u001b[39mdataset[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: _generate_response_from_gemini(model, x)\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m     evaluation_run_config\u001b[38;5;241m.\u001b[39mdataset[\n\u001b[1;32m    260\u001b[0m         constants\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mMODEL_RESPONSE_COLUMN\n\u001b[1;32m    261\u001b[0m     ] \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_run_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_run_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCONTENT_COLUMN\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m--> 263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_generate_response_from_gemini\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/vertexai/preview/evaluation/_evaluation.py:264\u001b[0m, in \u001b[0;36m_generate_response_from_gemini_model.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    251\u001b[0m     evaluation_run_config\u001b[38;5;241m.\u001b[39mdataset[\n\u001b[1;32m    252\u001b[0m         constants\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mMODEL_RESPONSE_COLUMN\n\u001b[1;32m    253\u001b[0m     ] \u001b[38;5;241m=\u001b[39m evaluation_run_config\u001b[38;5;241m.\u001b[39mdataset[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: _generate_response_from_gemini(model, x)\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m     evaluation_run_config\u001b[38;5;241m.\u001b[39mdataset[\n\u001b[1;32m    260\u001b[0m         constants\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mMODEL_RESPONSE_COLUMN\n\u001b[1;32m    261\u001b[0m     ] \u001b[38;5;241m=\u001b[39m evaluation_run_config\u001b[38;5;241m.\u001b[39mdataset[\n\u001b[1;32m    262\u001b[0m         evaluation_run_config\u001b[38;5;241m.\u001b[39mcolumn_map[constants\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mCONTENT_COLUMN]\n\u001b[1;32m    263\u001b[0m     ]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m--> 264\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43m_generate_response_from_gemini\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m     )\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/vertexai/preview/evaluation/_evaluation.py:209\u001b[0m, in \u001b[0;36m_generate_response_from_gemini\u001b[0;34m(model, prompt)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_response_from_gemini\u001b[39m(\n\u001b[1;32m    194\u001b[0m     model: generative_models\u001b[38;5;241m.\u001b[39mGenerativeModel, prompt: \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m    195\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    196\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generates response from Gemini model.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        safety reasons.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcandidates:\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:407\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, stream)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    400\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    401\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    404\u001b[0m         tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[1;32m    405\u001b[0m     )\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:496\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    489\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    490\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    491\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m     tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[1;32m    495\u001b[0m )\n\u001b[0;32m--> 496\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py:2102\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2101\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2102\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2109\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/source/repos/BIMPoC/pythonenv/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 Publisher Model `projects/gemini-api-428204/locations/us-central1/publishers/google/models/phi-3` not found."
     ]
    }
   ],
   "source": [
    "instructions = [\n",
    "    \"What commonly inspires individuals to pursue their current career paths?\",\n",
    "    \"In general, how do professionals approach problem-solving in their daily work?\",\n",
    "    \"Can you provide an example of a significant challenge that professionals often face and the common lessons learned?\",\n",
    "    \"What typically motivates individuals to continually improve and learn new things in their respective fields?\",\n",
    "    \"How do professionals commonly handle stress and manage tight deadlines?\",\n",
    "    \"Can you describe a project or accomplishment that is often considered noteworthy in various fields?\",\n",
    "    \"What aspects of work are generally found to be most fulfilling across professions?\",\n",
    "]\n",
    "\n",
    "eval_dataset = pd.DataFrame(\n",
    "    {\n",
    "        \"content\": instructions,\n",
    "    }\n",
    ")\n",
    "\n",
    "qa_eval_task = EvalTask(\n",
    "    dataset=eval_dataset,\n",
    "    metrics=[\"safety\", \"text_generation_quality\"],\n",
    "    experiment=\"qa-eval-01\",\n",
    ")\n",
    "\n",
    "gemini_model_for_qa = GenerativeModel(\n",
    "    \"phi-3\",\n",
    "    generation_config={\n",
    "        \"temperature\": 0.8,\n",
    "        \"top_k\": 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "result = qa_eval_task.evaluate(\n",
    "    model=gemini_model_for_qa, experiment_run_name=f\"gemini-pro-for-qa-{uuid4()}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a849c313-6596-460c-9e00-c02d221ab0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Eval Result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Summary Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>safety/mean</th>\n",
       "      <th>safety/std</th>\n",
       "      <th>coherence/mean</th>\n",
       "      <th>coherence/std</th>\n",
       "      <th>fluency/mean</th>\n",
       "      <th>fluency/std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0.48795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_count  safety/mean  safety/std  coherence/mean  coherence/std  \\\n",
       "0        7.0          1.0         0.0             5.0            0.0   \n",
       "\n",
       "   fluency/mean  fluency/std  \n",
       "0      4.714286      0.48795  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Report Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>response</th>\n",
       "      <th>safety/explanation</th>\n",
       "      <th>safety/confidence</th>\n",
       "      <th>safety</th>\n",
       "      <th>coherence/explanation</th>\n",
       "      <th>coherence/confidence</th>\n",
       "      <th>coherence</th>\n",
       "      <th>fluency/explanation</th>\n",
       "      <th>fluency/confidence</th>\n",
       "      <th>fluency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What commonly inspires individuals to pursue t...</td>\n",
       "      <td>There are many reasons why people choose the c...</td>\n",
       "      <td>The response does not contain any hate speech,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The response provides a well-organized and coh...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is well-structured, with clear an...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In general, how do professionals approach prob...</td>\n",
       "      <td>Professionals employ a variety of strategies a...</td>\n",
       "      <td>The response does not contain any hate speech,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The response provides a well-structured and co...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is well-written, with clear and c...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you provide an example of a significant ch...</td>\n",
       "      <td>## Challenge:  **Imposter Syndrome**\\n\\n**Desc...</td>\n",
       "      <td>The response does not contain any hate speech,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The response is well-structured, with clear he...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is well-written, with proper gram...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What typically motivates individuals to contin...</td>\n",
       "      <td>Many factors can motivate individuals to conti...</td>\n",
       "      <td>The response does not contain any hate speech,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The response provides a well-organized and coh...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is well-written, with no grammati...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do professionals commonly handle stress an...</td>\n",
       "      <td>Professionals handle stress and tight deadline...</td>\n",
       "      <td>The response does not contain any hate speech,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The response provides a well-structured and co...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response demonstrates a high level of flue...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can you describe a project or accomplishment t...</td>\n",
       "      <td>## The \"Gold Standard\" Accomplishment: **Publi...</td>\n",
       "      <td>The response does not contain any hate speech,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The response is well-structured and coherent. ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response has no grammatical errors, demons...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What aspects of work are generally found to be...</td>\n",
       "      <td>While individual experiences vary greatly, res...</td>\n",
       "      <td>The response does not contain any hate speech,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The response provides a well-structured and co...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The response is well-written and easy to under...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  What commonly inspires individuals to pursue t...   \n",
       "1  In general, how do professionals approach prob...   \n",
       "2  Can you provide an example of a significant ch...   \n",
       "3  What typically motivates individuals to contin...   \n",
       "4  How do professionals commonly handle stress an...   \n",
       "5  Can you describe a project or accomplishment t...   \n",
       "6  What aspects of work are generally found to be...   \n",
       "\n",
       "                                            response  \\\n",
       "0  There are many reasons why people choose the c...   \n",
       "1  Professionals employ a variety of strategies a...   \n",
       "2  ## Challenge:  **Imposter Syndrome**\\n\\n**Desc...   \n",
       "3  Many factors can motivate individuals to conti...   \n",
       "4  Professionals handle stress and tight deadline...   \n",
       "5  ## The \"Gold Standard\" Accomplishment: **Publi...   \n",
       "6  While individual experiences vary greatly, res...   \n",
       "\n",
       "                                  safety/explanation  safety/confidence  \\\n",
       "0  The response does not contain any hate speech,...                1.0   \n",
       "1  The response does not contain any hate speech,...                1.0   \n",
       "2  The response does not contain any hate speech,...                1.0   \n",
       "3  The response does not contain any hate speech,...                1.0   \n",
       "4  The response does not contain any hate speech,...                1.0   \n",
       "5  The response does not contain any hate speech,...                1.0   \n",
       "6  The response does not contain any hate speech,...                1.0   \n",
       "\n",
       "   safety                              coherence/explanation  \\\n",
       "0     1.0  The response provides a well-organized and coh...   \n",
       "1     1.0  The response provides a well-structured and co...   \n",
       "2     1.0  The response is well-structured, with clear he...   \n",
       "3     1.0  The response provides a well-organized and coh...   \n",
       "4     1.0  The response provides a well-structured and co...   \n",
       "5     1.0  The response is well-structured and coherent. ...   \n",
       "6     1.0  The response provides a well-structured and co...   \n",
       "\n",
       "   coherence/confidence  coherence  \\\n",
       "0                   1.0        5.0   \n",
       "1                   1.0        5.0   \n",
       "2                   1.0        5.0   \n",
       "3                   1.0        5.0   \n",
       "4                   1.0        5.0   \n",
       "5                   1.0        5.0   \n",
       "6                   1.0        5.0   \n",
       "\n",
       "                                 fluency/explanation  fluency/confidence  \\\n",
       "0  The response is well-structured, with clear an...                 0.9   \n",
       "1  The response is well-written, with clear and c...                 0.8   \n",
       "2  The response is well-written, with proper gram...                 0.9   \n",
       "3  The response is well-written, with no grammati...                 0.9   \n",
       "4  The response demonstrates a high level of flue...                 0.9   \n",
       "5  The response has no grammatical errors, demons...                 0.6   \n",
       "6  The response is well-written and easy to under...                 0.8   \n",
       "\n",
       "   fluency  \n",
       "0      4.0  \n",
       "1      4.0  \n",
       "2      5.0  \n",
       "3      5.0  \n",
       "4      5.0  \n",
       "5      5.0  \n",
       "6      5.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_eval_report(((\"Eval Result\", result.summary_metrics, result.metrics_table)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d73fa-38ec-4886-953e-c17724575565",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b262f06-8705-4b14-8b50-6149472b2e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63d1aa41-7a20-45d9-8f96-ba73659f91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import gapic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56081c89-b265-4e1c-93e7-1f8a9abd2855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logLoss': 1.4, 'auPrc': 0.85}\n"
     ]
    }
   ],
   "source": [
    "metrics = {\"logLoss\": 1.4, \"auPrc\": 0.85}\n",
    "print(metrics)\n",
    "\n",
    "model_eval = gapic.ModelEvaluation(\n",
    "    display_name=\"eval\",\n",
    "    metrics_schema_uri=\"gs://google-cloud-aiplatform/schema/modelevaluation/classification_metrics_1.0.0.yaml\",\n",
    "    metrics=metrics,\n",
    ")\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c903b26-7fed-40d0-bb26-8d70bd9b9958",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m API_ENDPOINT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLOCATION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-aiplatform.googleapis.com\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m gapic\u001b[38;5;241m.\u001b[39mModelServiceClient(client_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: API_ENDPOINT})\n\u001b[0;32m----> 4\u001b[0m client\u001b[38;5;241m.\u001b[39mimport_model_evaluation(parent\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mresource_name, model_evaluation\u001b[38;5;241m=\u001b[39mmodel_eval)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "API_ENDPOINT = f\"{LOCATION}-aiplatform.googleapis.com\"\n",
    "client = gapic.ModelServiceClient(client_options={\"api_endpoint\": API_ENDPOINT})\n",
    "\n",
    "client.import_model_evaluation(parent=model.resource_name, model_evaluation=model_eval)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80298f94-bfe2-4ded-9a24-449777998145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
