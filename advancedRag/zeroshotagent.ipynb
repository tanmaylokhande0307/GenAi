{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42386076-475d-4b88-962a-3baf7bdd1892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 -q install pandas numpy langchain langsmith langgraph langchain_openai langchain-community langchainhub langchain-openai langchain-chroma bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956ac916-f0b4-41af-937f-da1294c5fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 -q install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3173ed66-0976-45ef-960b-b92014536960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tranformers[sentencepiece] (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tranformers[sentencepiece]\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tranformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acb93763-8045-4918-bcd3-07791b56c729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0f4da50-9196-4ebb-b3cf-c988f1ed2786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f19fab7-11a8-4536-aa40-adf3ef297528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "HUGGINGFACE_API_TOKEN=os.environ.get(\"HUGGINGFACE_API_TOKEN\")\n",
    "TAVILY_API_KEY=os.environ.get(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beaabe0e-b7e7-4d76-ad66-ddd23ff54a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.huggingface_endpoint import HuggingFaceEndpoint\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adfe50c1-d0ae-48aa-bf29-341b9fd60a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debian/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 5 files: 100%|████████████████████████| 5/5 [00:00<00:00, 67216.41it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = FastEmbedEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12eac64a-813a-4826-9914-499974aa0f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debian/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from langchain-huggingface package and should be used instead. To use it run `pip install -U from langchain-huggingface` and import as `from from langchain_huggingface import llms import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n",
      "WARNING! max_new_token is not default parameter.\n",
      "                    max_new_token was transferred to model_kwargs.\n",
      "                    Please make sure that max_new_token is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/debian/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    endpoint_url=\"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    task=\"text_generation\",\n",
    "    max_new_token=6096,\n",
    "    huggingfacehub_api_token=HUGGINGFACE_API_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41615460-2e2e-4859-b68c-fd5bd3d3d9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q -U requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e43e09b-d552-400e-beaf-d40ef53bc21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q -U scrapy selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7195feb4-f2e7-4c59-a6bc-a95e51feb65a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'webdriver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chrome_options \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241m.\u001b[39mChromeOptions()\n\u001b[1;32m      2\u001b[0m chrome_options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--headless\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m chrome_options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--no-sandbox\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'webdriver' is not defined"
     ]
    }
   ],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9d6e7c2-81b4-4eb7-95e6-3bd06b5307c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numexpr\n",
      "  Obtaining dependency information for numexpr from https://files.pythonhosted.org/packages/21/53/1b312fd243799c4b080c81692b7bd81c9400a2da12291d0447db70cfd635/numexpr-2.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numexpr-2.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /home/debian/.local/lib/python3.11/site-packages (from numexpr) (1.26.4)\n",
      "Downloading numexpr-2.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.3/378.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numexpr\n",
      "Successfully installed numexpr-2.10.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba99ed9c-fb35-49d7-85b6-eb1c082f999f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debian/.local/lib/python3.11/site-packages/langchain/chains/llm_math/base.py:57: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMMathChain\n",
    "from langchain.agents import Tool\n",
    "\n",
    "llm_math = LLMMathChain(llm=llm)\n",
    "\n",
    "# initialize the math tool\n",
    "math_tool = Tool(\n",
    "    name='Calculator',\n",
    "    func=llm_math.run,\n",
    "    description='Useful for when you need to answer questions about math.'\n",
    ")\n",
    "# when giving tools to LLM, we must pass as list of tools\n",
    "tools = [math_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b6c3818-b014-47da-91cc-2cdd6661f29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Calculator', 'Useful for when you need to answer questions about math.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].name, tools[0].description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24e996e1-1f91-4d67-959e-51a27b9020f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=HuggingFaceEndpoint(endpoint_url='https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2', huggingfacehub_api_token='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', model_kwargs={'max_new_token': 6096}, model='https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2', client=<InferenceClient(model='https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>, async_client=<InferenceClient(model='https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>, task='text_generation')), llm=HuggingFaceEndpoint(endpoint_url='https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2', huggingfacehub_api_token='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', model_kwargs={'max_new_token': 6096}, model='https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2', client=<InferenceClient(model='https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>, async_client=<InferenceClient(model='https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>, task='text_generation'))>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2961d77-02f9-4544-9f5c-affd89b360c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    ['llm-math'],\n",
    "    llm=llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82f94acb-f211-420d-a8ed-d5c68c44a35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debian/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "\tagent=\"zero-shot-react-description\",\n",
    "\ttools=tools,\n",
    "\tllm=llm,\n",
    "\tverbose=True,\n",
    "\tmax_iterations=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8edc06d2-8be9-4291-8c39-2c5edbf0d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to calculate the exponent first, then the multiplication, and finally the square\n",
      "Action: Calculator(4.5*2.1, callbacks=None, tags=None, metadata=None, power=2.2)\n",
      "Action Input: (4.5*2.1, 2.2)\u001b[0m\n",
      "Observation: Calculator(4.5*2.1, callbacks=None, tags=None, metadata=None, power=2.2) is not a valid tool, try one of [Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the calculator multiple times to solve the problem\n",
      "Action: Calculator(4.5, callbacks=None, tags=None, metadata=None)\n",
      "Action Input: 4.5\u001b[0m\n",
      "Observation: Calculator(4.5, callbacks=None, tags=None, metadata=None) is not a valid tool, try one of [Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate 4.5 first\n",
      "Action: Calculator(4.5, callbacks=None, tags=None, metadata=None)\n",
      "Action Input: None\u001b[0m\n",
      "Observation: Calculator(4.5, callbacks=None, tags=None, metadata=None) is not a valid tool, try one of [Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is (4.5*2.1)^2.2?',\n",
       " 'output': 'Agent stopped due to iteration limit or time limit.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7db39040-539a-4e9e-a8ca-cb797879f1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Mary has 4 apples, Giorgio brings 2.5 boxes of apples (each box contains 8 apples). Let me calculate the number of apples Giorgio brings.\n",
      "Action: Calculator\n",
      "Action Input: 2.5 * 8\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 20.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Mary has 4 apples and we have 20 apples from Giorgio.\n",
      "Final Answer: We have 24 apples in total.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'if Mary has four apples and Giorgio brings two and a half apple boxes (apple box contains eight apples), how many apples do we have?',\n",
       " 'output': 'We have 24 apples in total.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"if Mary has four apples and Giorgio brings two and a half apple \"\n",
    "                \"boxes (apple box contains eight apples), how many apples do we \"\n",
    "                \"have?\")\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6b5a1e7-56d6-4f38-9086-93fff1a8487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"{query}\"\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "# initialize the LLM tool\n",
    "llm_tool = Tool(\n",
    "    name='Language Model',\n",
    "    func=llm_chain.invoke,\n",
    "    description='use this tool for general purpose queries and logic'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f6ad46d-648b-4d16-8087-b28978553c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='Language Model', description='use this tool for general purpose queries and logic', func=<bound method RunnableSequence.invoke of PromptTemplate(input_variables=['query'], template='{query}')\n",
       "| HuggingFaceEndpoint(endpoint_url='https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2', huggingfacehub_api_token='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', model_kwargs={'max_new_token': 6096}, model='https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2', client=<InferenceClient(model='https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>, async_client=<InferenceClient(model='https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>, task='text_generation')>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e52bf42-cd11-430c-8342-8d74a3b060d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.append(llm_tool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4df10e61-55a5-440b-97c2-1e867baa503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85232250-db98-42b0-9770-ce52ea52ac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I can use the Language Model to find the answer\n",
      "Action: Language Model\n",
      "Action Input: What is the capital of Norway?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "Norway's capital city is Oslo. It is the largest city in Norway and is located along the Oslofjord in the southeastern part of the country. Oslo is known for its vibrant arts scene, rich cultural history, and stunning natural beauty. Some popular attractions in Oslo include the Viking Ship Museum, the Vigeland Sculpture Park, and the Oslo Opera House.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The capital city of Norway is Oslo.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the capital of Norway?',\n",
       " 'output': 'The capital city of Norway is Oslo.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"what is the capital of Norway?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d18d2a51-5563-47ad-91a4-09e07102fd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to calculate the power first, and then calculate the square\n",
      "Action: Calculator\n",
      "Action Input: (4.5*2.1)**2.2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 139.94261298333066\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The answer is approximately 139.94.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is (4.5*2.1)^2.2?',\n",
       " 'output': 'The answer is approximately 139.94.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694adf4-4b6f-491a-95ea-ccbec788c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
