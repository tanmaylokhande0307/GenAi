{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "82f21cb4-a421-4f2c-acfe-42df173d83e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 -q install pandas numpy langchain langsmith langgraph langchain_openai langchain-community langchainhub langchain-openai langchain-chroma bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "511e480b-9af9-4925-9295-6194096c21e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 -q install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9aa78643-ce29-4e1e-a317-e26fff4987bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tranformers[sentencepiece] (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tranformers[sentencepiece]\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tranformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dc01077e-3d24-47c4-975f-f938d3f93f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fastembed\n",
      "  Obtaining dependency information for fastembed from https://files.pythonhosted.org/packages/d8/bb/fa7620fd49aa073c16d410e6cbdb4f992b0c52135f4f12ca0b1dbff47287/fastembed-0.2.7-py3-none-any.whl.metadata\n",
      "  Downloading fastembed-0.2.7-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting huggingface-hub<0.21,>=0.20 (from fastembed)\n",
      "  Obtaining dependency information for huggingface-hub<0.21,>=0.20 from https://files.pythonhosted.org/packages/28/03/7d3c7153113ec59cfb31e3b8ee773f5f420a0dd7d26d40442542b96675c3/huggingface_hub-0.20.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting loguru<0.8.0,>=0.7.2 (from fastembed)\n",
      "  Obtaining dependency information for loguru<0.8.0,>=0.7.2 from https://files.pythonhosted.org/packages/03/0a/4f6fed21aa246c6b49b561ca55facacc2a44b87d65b8b92362a8e99ba202/loguru-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/debian/.local/lib/python3.11/site-packages (from fastembed) (1.26.4)\n",
      "Collecting onnx<2.0.0,>=1.15.0 (from fastembed)\n",
      "  Obtaining dependency information for onnx<2.0.0,>=1.15.0 from https://files.pythonhosted.org/packages/e8/e3/2eba2167d36a845af16255fe9c2a0a22a7034f3765109790cab91038c167/onnx-1.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading onnx-1.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: onnxruntime<2.0.0,>=1.17.0 in /home/debian/.local/lib/python3.11/site-packages (from fastembed) (1.18.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /home/debian/.local/lib/python3.11/site-packages (from fastembed) (2.32.1)\n",
      "Collecting tokenizers<0.16,>=0.15 (from fastembed)\n",
      "  Obtaining dependency information for tokenizers<0.16,>=0.15 from https://files.pythonhosted.org/packages/15/0b/c09b2c0dc688c82adadaa0d5080983de3ce920f4a5cbadb7eaa5302ad251/tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in /home/debian/.local/lib/python3.11/site-packages (from fastembed) (4.66.4)\n",
      "Requirement already satisfied: filelock in /home/debian/.local/lib/python3.11/site-packages (from huggingface-hub<0.21,>=0.20->fastembed) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/debian/.local/lib/python3.11/site-packages (from huggingface-hub<0.21,>=0.20->fastembed) (2024.5.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/debian/.local/lib/python3.11/site-packages (from huggingface-hub<0.21,>=0.20->fastembed) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/debian/.local/lib/python3.11/site-packages (from huggingface-hub<0.21,>=0.20->fastembed) (4.11.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/debian/.local/lib/python3.11/site-packages (from huggingface-hub<0.21,>=0.20->fastembed) (23.2)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/debian/.local/lib/python3.11/site-packages (from onnx<2.0.0,>=1.15.0->fastembed) (4.25.3)\n",
      "Requirement already satisfied: coloredlogs in /home/debian/.local/lib/python3.11/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/debian/.local/lib/python3.11/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed) (24.3.25)\n",
      "Requirement already satisfied: sympy in /home/debian/.local/lib/python3.11/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed) (1.12)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/debian/.local/lib/python3.11/site-packages (from requests<3.0,>=2.31->fastembed) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/debian/.local/lib/python3.11/site-packages (from requests<3.0,>=2.31->fastembed) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/debian/.local/lib/python3.11/site-packages (from requests<3.0,>=2.31->fastembed) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/debian/.local/lib/python3.11/site-packages (from requests<3.0,>=2.31->fastembed) (2024.2.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/debian/.local/lib/python3.11/site-packages (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->fastembed) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/debian/.local/lib/python3.11/site-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->fastembed) (1.3.0)\n",
      "Downloading fastembed-0.2.7-py3-none-any.whl (27 kB)\n",
      "Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hDownloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnx-1.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: onnx, loguru, huggingface-hub, tokenizers, fastembed\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.23.1\n",
      "    Uninstalling huggingface-hub-0.23.1:\n",
      "      Successfully uninstalled huggingface-hub-0.23.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.41.2 requires huggingface-hub<1.0,>=0.23.0, but you have huggingface-hub 0.20.3 which is incompatible.\n",
      "transformers 4.41.2 requires tokenizers<0.20,>=0.19, but you have tokenizers 0.15.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fastembed-0.2.7 huggingface-hub-0.20.3 loguru-0.7.2 onnx-1.16.1 tokenizers-0.15.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2d15b7c6-e956-4f48-974a-d84cebf87cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faiss-cpu\n",
      "  Obtaining dependency information for faiss-cpu from https://files.pythonhosted.org/packages/b5/be/23bfb89fdeacf133dffd905787c620740d89d3fd35ffcf98bdd31f9348f7/faiss_cpu-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading faiss_cpu-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: numpy in /home/debian/.local/lib/python3.11/site-packages (from faiss-cpu) (1.26.4)\n",
      "Downloading faiss_cpu-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "32fff534-b27d-40de-999b-27676b104f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.huggingface_endpoint import HuggingFaceEndpoint\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e2f731e8-929e-46d5-a1e6-a4ae04b4029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    \"https://blog.langchain.dev/langchain-v0-1-0/\"\n",
    ")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bc809c8c-9f98-462a-a3bc-661fb5389efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 700,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "54aa7e35-a0fa-4d3c-869f-93dcaa4cde80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debian/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Fetching 5 files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = FastEmbedEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "98150f3c-c8a6-4f9e-946d-088de126f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vector_store = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8fcf7105-23a0-43a6-aec9-a4afa0630fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c8646fdf-7e53-40a1-823e-bf939b0af73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents = retriever.invoke(\"Why did they change to version 0.1.0?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "858969a9-3f53-4ff5-aaa7-e844c923401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "retrieval_qa_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ad79faf8-2f33-49d7-a937-c643144cd7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'I don't know':\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "aa95dc46-b930-49b6-b154-9365f1123804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "primary_qa_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "retrieval_augmented_qa_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e6fb896b-7979-416b-a764-03292d9cd3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_new_token is not default parameter.\n",
      "                    max_new_token was transferred to model_kwargs.\n",
      "                    Please make sure that max_new_token is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/debian/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    endpoint_url=\"<get mistral api key from https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2>\",\n",
    "    task=\"text_generation\",\n",
    "    max_new_token=6096,\n",
    "    huggingfacehub_api_token=\"<get huggingface token>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3ed68637-ffeb-4020-9d65-a79314032d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The major changes in v0.1.0 include separating out langchain-core and partner packages, introducing a new versioning standard, improving stability, and focusing on core functionality and documentation.\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the major changes in v0.1.0?\"\n",
    "\n",
    "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
    "\n",
    "print(result[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aada056-a1a7-4d05-94b6-6cf11ea7fa7f",
   "metadata": {},
   "source": [
    "##https://www.youtube.com/watch?v=Anr1br0lLz8&list=PLrSHiQgy4VjGjrLbBc9grlnXgkOeP4tQ-&index=2\n",
    "following above playlist\n",
    "\n",
    "AI Markerspace channel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
