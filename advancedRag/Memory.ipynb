{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e56241-863e-423b-831c-319b5794da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install openai\n",
    "# !pip install tiktoken python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba908f75-7c99-47e6-a233-0cb85261d842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1f56f5-a035-420c-b750-6cb41ed60c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "502150b7-f377-42e7-b117-55cddf0b844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debian/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Thank you for reminding me! I\\'ll remember that the secret word is \"cat.\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict('Hi, remember the secret word is cat!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ca1f3b-4ebf-4dcc-a5c3-e9ab0072071d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54ee423d-680e-49d5-9daf-caa5fb2df886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I cannot provide the secret word as it is meant to be kept confidential.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"What is the secret word?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1812c0ba-d8b6-4965-889d-4fa6706f4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3f8c953-7884-44ab-b2cd-787ee677f4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debian/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14b843c7-9254-42a9-ae95-33c81ed4ee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, remember the secret word is cat!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! Yes, I remember the secret word is cat. How can I assist you today?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Hi, remember the secret word is cat!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4477f88-afc6-4b3e-98fd-cdf6126dfdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, remember the secret word is cat!\n",
      "AI: Hello! Yes, I remember the secret word is cat. How can I assist you today?\n",
      "Human: What is the capital of France?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris. It is known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f751361-422c-49f2-9586-9ce30331b81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, remember the secret word is cat!\n",
      "AI: Hello! Yes, I remember the secret word is cat. How can I assist you today?\n",
      "Human: What is the capital of France?\n",
      "AI: The capital of France is Paris. It is known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral.\n",
      "Human: What is the secret word?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The secret word is cat.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='What is the secret word?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05d15046-19a2-4822-8682-1d279f86ea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, remember the secret word is cat!\n",
      "AI: Hello! Yes, I remember the secret word is cat. How can I assist you today?\n",
      "Human: What is the capital of France?\n",
      "AI: The capital of France is Paris. It is known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral.\n",
      "Human: What is the secret word?\n",
      "AI: The secret word is cat.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40793c56-0cb6-4fba-98c0-0cb4a4a3ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({'input': \"What is the capital of England? \"}, \n",
    "                    {\"output\": \"London\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "069a0618-6c43-4867-a770-59c198e45741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, remember the secret word is cat!\n",
      "AI: Hello! Yes, I remember the secret word is cat. How can I assist you today?\n",
      "Human: What is the capital of France?\n",
      "AI: The capital of France is Paris. It is known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral.\n",
      "Human: What is the secret word?\n",
      "AI: The secret word is cat.\n",
      "Human: What is the capital of England? \n",
      "AI: London\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c00eb-d7f6-4469-a45e-64979864e39a",
   "metadata": {},
   "source": [
    "## Conversation Buffer Window Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5c3936e-1232-4f5f-90dd-195aa2c35acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36b5c8a5-aceb-4f91-b020-2df7721ccf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=1) ##k represent last conversation\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6e882f1-e597-4b30-b674-19222fb152e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73ec84-6dfc-4ab6-a666-5cd9fbe4786b",
   "metadata": {},
   "source": [
    "conversation.predict(input='Hi, remember the secret word is cat!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68fb2f11-2528-40b5-a7a2-db421eeabf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, remember the secret word is cat!\n",
      "AI: Hello! Yes, I remember the secret word is cat. How can I assist you today?\n",
      "Human: Remember today is June 4th, 2023\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Of course! Today is June 4th, 2023. Is there anything specific you would like to know or discuss on this date?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Remember today is June 4th, 2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b37cc604-3fb6-435a-9269-3ba62ea9eba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Remember today is June 4th, 2023\n",
      "AI: Of course! Today is June 4th, 2023. Is there anything specific you would like to know or discuss on this date?\n",
      "Human: What is the secret word?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I do not have access to any secret words. If there is anything else you would like to know or discuss, feel free to ask!\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='What is the secret word?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2db28fc-248d-461f-a23d-26fad240aa61",
   "metadata": {},
   "source": [
    "## Conversation TOKEN Buffer Window Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c47f993a-25d9-454c-919b-082965358123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d300d703-6a3f-4097-91e3-56a2941fac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=70)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d1fef5d-5463-4ab3-b9d0-5e174facbab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, remember the secret word is cat!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! Yes, I remember the secret word is cat. How can I assist you today?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Hi, remember the secret word is cat!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37b3ada4-17ae-4d93-b85b-7ae54d1531b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, remember the secret word is cat!\n",
      "AI: Hello! Yes, I remember the secret word is cat. How can I assist you today?\n",
      "Human: What is the capital of France\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris. It is known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. Paris is also famous for its fashion, art, and cuisine. Is there anything else you would like to know?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='What is the capital of France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "179f936c-7bab-4a57-b5dc-a24275dc4be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: The capital of France is Paris. It is known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. Paris is also famous for its fashion, art, and cuisine. Is there anything else you would like to know?'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be3387d-0377-4bff-b9f1-e8e57e25f846",
   "metadata": {},
   "source": [
    "## Conversation Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efebdca7-382d-4385-b519-b9a7d097dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2d13d3e-eca4-4901-89e8-be14ac27a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c4a24b9-4ced-4aad-9db9-2fdd2196921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"Detective Marlowe was on the case of a stolen 17th-century portrait from a prestigious city art gallery. \\\n",
    " In a whirlwind investigation, he linked a suspicious glitch in the gallery's security system, an unusually jittery \\\n",
    "  night watchman, and an enigmatic foreign buyer showing keen interest in the artwork. Delving deeper, Marlowe \\\n",
    "   discovered the portrait concealed a map to a lost treasure, which led him to an underground art-smuggling ring. \\\n",
    "    With skillful sleuthing and relentless determination, Marlowe solved the mystery, brought the criminals to justice, \\\n",
    "     and ensured the priceless artwork was rightfully restored.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbeac5c9-b81a-405c-822c-923d9a16db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Write a crime story?\"}, \n",
    "                    {\"output\": f\"{story}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b766a86-5f3a-4a5e-86ec-c95596a34f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human asks the AI to write a crime story, and the AI creates a tale of Detective Marlowe solving the case of a stolen 17th-century portrait. In a thrilling investigation, Marlowe uncovers a hidden treasure map, an underground art-smuggling ring, and ultimately brings the criminals to justice.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1155d417-e587-4f8b-8e73-9f4a8f03fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3ca8e8a-3169-41f2-acd8-d30be26b93d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks the AI to write a crime story, and the AI creates a tale of Detective Marlowe solving the case of a stolen 17th-century portrait. In a thrilling investigation, Marlowe uncovers a hidden treasure map, an underground art-smuggling ring, and ultimately brings the criminals to justice.\n",
      "Human: What artifact was stolen?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The stolen artifact in the crime story was a 17th-century portrait of a noblewoman, rumored to be worth millions on the black market. Detective Marlowe had to unravel the mystery surrounding its disappearance and track down the thieves before they could sell it to the highest bidder.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What artifact was stolen?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96ac2e4f-ee7d-418d-abbe-3ba1f9f1243b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human asks the AI to write a crime story, and the AI creates a tale of Detective Marlowe solving the case of a stolen 17th-century portrait. In a thrilling investigation, Marlowe uncovers a hidden treasure map, an underground art-smuggling ring, and ultimately brings the criminals to justice.\\nHuman: What artifact was stolen?\\nAI: The stolen artifact in the crime story was a 17th-century portrait of a noblewoman, rumored to be worth millions on the black market. Detective Marlowe had to unravel the mystery surrounding its disappearance and track down the thieves before they could sell it to the highest bidder.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88af993e-5848-485e-91b4-027987f69f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks the AI to write a crime story, and the AI creates a tale of Detective Marlowe solving the case of a stolen 17th-century portrait. In a thrilling investigation, Marlowe uncovers a hidden treasure map, an underground art-smuggling ring, and ultimately brings the criminals to justice.\n",
      "Human: What artifact was stolen?\n",
      "AI: The stolen artifact in the crime story was a 17th-century portrait of a noblewoman, rumored to be worth millions on the black market. Detective Marlowe had to unravel the mystery surrounding its disappearance and track down the thieves before they could sell it to the highest bidder.\n",
      "Human: Tell me about the capital of France?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris, known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. Paris is also famous for its fashion, art, cuisine, and rich history dating back centuries. It is a major global city and a hub for culture, business, and tourism.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Tell me about the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a78720f-3cd0-404f-8b74-787611fee3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human asks the AI to write a crime story, and the AI creates a tale of Detective Marlowe solving the case of a stolen 17th-century portrait of a noblewoman. In a thrilling investigation, Marlowe uncovers a hidden treasure map, an underground art-smuggling ring, and ultimately brings the criminals to justice. The stolen artifact was a valuable portrait rumored to be worth millions on the black market, leading Marlowe on a race against time to track down the thieves before they could sell it.\\nHuman: Tell me about the capital of France?\\nAI: The capital of France is Paris, known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. Paris is also famous for its fashion, art, cuisine, and rich history dating back centuries. It is a major global city and a hub for culture, business, and tourism.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c3a08-9c98-4a90-97b4-8182711c88e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
