{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46d71f84-ff10-40cd-9759-699bf57aef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d02dd74d-167e-440d-a224-befb1afcdb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23f12f32-876f-45d8-960c-d7e83c07b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_vertexai import ChatVertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1ee60f7-769a-4e66-9819-a89fdc3437a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73062f60-d4e6-4512-b3de-46623949aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "vertexai.init(\n",
    "    project=\"bim-poc\",\n",
    "    location=\"us-central1\",\n",
    ")\n",
    "llm = ChatVertexAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e88469c1-3f4e-49a5-b6e2-c88787891acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOllama(model=\"llama2\")\n",
    "# prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "184004fd-be24-44b2-bbc1-898b0495deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8423ad1c-86cb-4bbb-9cc6-fe3fdcc3cf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the astronaut bring an extra pair of pants on his mission to Mars? \n",
      "\n",
      "In case he ripped his space-suit.  Did you like that one? I have another one: \n",
      "\n",
      "What do you call an astronaut who crashes into the moon? \n",
      "\n",
      "A crater-naut! ðŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"topic\": \"Space travel\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccbb7bf-0a06-4db4-8ecc-d99d494cf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ce563-1f1a-49f4-8b1b-37121e51b88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb1ca719-219d-4d0a-8d4d-2787951e9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q langchain-fireworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c889b9-4a79-428b-8b94-6049eade4f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_fireworks import ChatFireworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4b6690-91d9-4422-a39a-0845e36fde6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"FIREWORKS_API_KEY\"] = \"api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b960c725-d47a-4638-888b-c9d666be98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatFireworks(model=\"accounts/fireworks/models/firefunction-v2-rc\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61d35a56-5883-4f94-bf75-f3f3b8a64eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am an AI assistant. I am here to help you with any questions or tasks you may have. I am a machine learning model that has been trained on a large dataset of text and can generate human-like responses to a wide range of questions and prompts. I am constantly learning and improving, so please bear with me if I make any mistakes. I am here to help and provide information to the best of my ability.', response_metadata={'token_usage': {'prompt_tokens': 260, 'total_tokens': 346, 'completion_tokens': 86}, 'model_name': 'accounts/fireworks/models/firefunction-v2-rc', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run-83b675b8-454f-4c59-a504-01bd847844e3-0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = SystemMessage(content=\"You are to chat with the user.\")\n",
    "human_message = HumanMessage(content=\"Who are you?\")\n",
    "\n",
    "chat.invoke([system_message, human_message])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a89b6e0-0941-4964-babc-b4097a852bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
